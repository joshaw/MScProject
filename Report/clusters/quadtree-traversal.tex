% Created:  Thu 10 Jul 2014 04:22 PM
% Modified: Mon 11 Aug 2014 09:48 AM
% @author Josh Wainwright
% File name : quadtree-traversal.tex

\section{Quadtree Traversal}
\label{sec:quadtree_traversal}

Whether the quadtree is stored in memory as a recursive quadtree data
structure, or as hash table, Section~\ref{sub:hash_table_implementation}, the
most important and computationally intensive step is extracting the clusters at
the correct depth and disregarding those data points that can be attributed to
noise.

The quadtree numbering system chosen lends itself very well to analysis based
on spatial location and the proximity of neighbours to a given node being
examined.

\subsection{Algorithm Description}
\label{sub:algorithm_description}

The propagation algorithm is performed as follows:
\begin{enumerate}
	\item Choose a starting location that has not yet been checked.
	\item For this given starting location, the $n$ neighbours are checked for
		validity based on the conditions of the analysis (the way these
		neighbours are selected is discussed in
		Section~\ref{sub:choosing_neighbours}).
	\item If a node fails the check, then it is recorded as having done so and
		shall not be checked again. If it passes, then it is itself propagated.
		\begin{itemize}
			\item To be ``propagated'' means the perform this propagation
				algorithm using that node as the starting location.
		\end{itemize}
	\item When all nodes have been checked, return to step 1.
	\item The algorithm completes either when either;
	\begin{itemize}
		\item every one of the nodes in the image have been checked and
			included or ignored, or
		\item the cluster has ended, so all the neighbours of all checked nodes
			have failed the validity tests and no further starting locations
			were found or specified.
	\end{itemize}
\end{enumerate}

This process is shown graphically in Figure~\ref{fig:propogation}. Here, and
from now on, blue nodes are nodes that either need to be checked or are
currently being checked; red are nodes that have been checked and have been
included in the cluster; question marks ({\footnotesize?}) represent the
neighbours of the blue nodes that will have to be checked to determine if it is
included or not and crosses ({\footnotesize x}) represent neighbours that have
been checked and excluded.

\begin{lstlisting}
	public |propagate()| {

		node[] start_locations = get_start_locations() (*@\label{eql:a}@*)
		for each node in start_locations {
			propagate(node)
		}
	}

	private |propagate(node)| {

		if (not node.inCluster()) { (*@\label{eql:b}@*)
			node[] neighbours = get_node_neighbours(node)

			for each neighbour in neighbours { (*@\label{eql:c}@*)
				propagate(neighbour)
			}
		}
	}
\end{lstlisting}

\paragraph{Line~\ref{eql:a}} A set of starting locations is selected based on
some heuristic that determines if a node is deep enough in the tree to be used
as a starting location.

\paragraph{Line~\ref{eql:b}} Nodes are only propagated if they have not already
been included in a cluster. If this were not the case, then clusters would
overlap.

\paragraph{Line~\ref{eql:c}} Each of the neighbours of the current node is
propagated. The method of choosing neighbours determines how far the cluster
can spread, and is separated from the clustering algorithm.

\begin{figure}[tbhp]
	\centering
	\includegraphics[width=7cm]{propogation.pdf}
	\caption{For a starting location, (a), in an image, no information is known
		and so the neighbours are checked. Some of these are found to be part
		of the cluster, others are rejected. The ones that are included are
		then, themselves, checked and so on. As the cluster grows, (b), (c) and
		(d), the number of checked nodes increases.}\label{fig:propogation}
\end{figure}

When discovering clusters via this propagation technique, care must be taken to
avoid a run-away situation where every node in the tree gets included. This
would happen when looking at the neighbours of a node and blindly including
them. Since every internal node has exactly four neighbours, the propagation
would terminate only when reaching the edge nodes.

Instead, the depth of the node must be considered. Again, the simplest method
is not sufficient. If the propagation is limited to a given node depth, even if
this is not the same as the deepest node, the size of any clusters that are
identified will be limited, as shown in Figure~\ref{fig:propogation-halting}.
Since the depth to consider is not able to change, when the neighbours of the
blue node are checked, no correct neighbours are found and so the process
terminates. When able to view the larger structure of the nodes, however, it is
clear that the structure continues beyond the gap.

\begin{figure}[tbhp]
	\centering
	\begin{subfigure}[c]{5.2cm}
		\includegraphics[width=\linewidth]{propogation-halting.pdf}
		\caption{}\label{fig:propogation-halting}
	\end{subfigure}%
	\quad
	\begin{subfigure}[c]{3.2cm}
		\includegraphics[width=\linewidth]{propogation-levels.pdf}
		\caption{}\label{fig:propogation-levels}
	\end{subfigure}
	\caption{Considerations regarding quadtree levels that will be accepted
		when propagating a node in a quadtree. \subref{fig:propogation-halting}
		If the depth range that specifies how far up the tree to look for valid
		neighbours is too small then a cluster might be terminated too soon.
		\subref{fig:propogation-levels}~(i) a depth range of two and, (ii) a
		depth range of three.}\label{fig:prop-levels-halting}
\end{figure}

To avoid this, a certain amount of leniency must be given when deciding what
constitutes a neighbour. Given an appropriate value, this would allow both of
the larger white cells in Figure~\ref{fig:propogation-halting} to be included.

The term \emph{depth range} shall define the levels that are to be considered
when choosing neighbours with respect to a target depth. Since clusters are
being considered as areas of increased density of points, all cells with a
depth greater than the target depth shall be allowed, so the purple cells in
Figure~\ref{fig:propogation-halting} would be included when the target depth is
the same as the depth of the included red cells. A depth range of zero is
equivalent to the situation above where only cells of a given depth are
considered. A depth range of 1 would mean that the white square in
Figure~\ref{fig:propogation-levels}\,(i) would be included but not in~(ii),
whereas a depth range of three would include both and so on.

\subsection{Clustering Start Locations}
\label{sub:clustering_start_locations}

In order for the algorithm to proceed correctly, a good initial node, a
starting location, must be chosen. Since the clusters to be found are regions
of high point density, it makes sense to start the clustering algorithm at the
point in the image with the highest point density. This should ensure that the
most defined cluster is always found with subsequent clusters being less dense,
and so less well defined.

When starting at the highest density node, i.e., the node which is at the
deepest level in the tree, propagating this node and then terminating; the
cluster shown in Figure~\ref{fig:single-cluster} is found. The file
\texttt{palm-1.txt} was used and generated this data in
\SI{457}{\milli\second}. This shows that the algorithm works correctly.
Altering the parameters that are used to generate the quadtree affects the size
of the nodes that are included in the cluster and the depth that is searched.

\begin{figure}[tbhp]
	\centering
	\begin{subfigure}[c]{4.2cm}
		\includegraphics[width=\textwidth]{single-cluster.png}
		\caption{}\label{fig:single-cluster-points}
	\end{subfigure}%
	\quad
	\begin{subfigure}[c]{4.2cm}
		\includegraphics[width=\textwidth]{single-cluster-lines.png}
		\caption{}\label{fig:single-cluster-lines}
	\end{subfigure}
	\caption{Inital versions of the clustering algorithm terminated immediately
		after finishing propagating the first cluster. This gives a useful test
		as to the correctness of the algorithm since there are no other
		clusters for this to collide with. It is useful to be able to check
		both \subref{fig:single-cluster-points} the points that were considered
		to be in the cluster and \subref{fig:single-cluster-lines} the nodes in
		the quadtree that were included and where the propagating algorithm
		stopped.}\label{fig:single-cluster}
\end{figure}

In order to find other clusters, the algorithm must be restarted with a new
starting location. This is chosen as the deepest node in the tree that is not
already included in a cluster. There are a number of different way to terminate
this process of finding new clusters:

\begin{itemize}

	\item Perform a set number of iterations. This performs well if the
		clusters to be located can be easily counted, but in the general case,
		this is not possible or desired. If the number of iterations is set to
		a high value, of the order of 50, the algorithm will continue to locate
		``clusters'' even if they do not exist and will eventually simply
		report the background noise as a cluster. To prevent this, a limit can
		be set on the depth a starting location must be in order to be valid.

	\item Continue iterating until a depth limit is reached. This is a more
		general form of the previous case, but for this case, the limit on the
		depth of a starting location will always be reached.

	\item Allow the user to make a number of starting point location selections
		manually. Since ImageJ allows multi-point region of interest (ROI)
		selections, the user could be asked to place a new ROI at the places
		they consider a reasonable place to find a cluster. The algorithm would
		then convert the locations of each of these ROI points into the
		relevant quadtree code and begin propagating from that node and
		terminate when all of the ROI's had been used.

\end{itemize}

% TODO why have we chosen what we have.

\begin{figure}[tbhp]
	\centering
	\begin{minipage}[c]{7cm}
		\fbox{\includegraphics[width=\textwidth]{multiple-clusters-colours.png}}
	\end{minipage}%
	\,
	\begin{minipage}[c]{1cm}
		\centering
		\begin{tabular}[b]{l}
			\cellcolor{lyellow}1 \\
			\cellcolor{lorange}2 \\
			\cellcolor{lbrown}3 \\
			\cellcolor{lgreen}4 \\
			\cellcolor{lblue}5 \\
			\cellcolor{lpurple}6 \\
			\cellcolor{lred}7 \\
			\cellcolor{silver}8 \\
			\cellcolor{lgrey}9 \\
		\end{tabular}
	\end{minipage}

	\caption{Initial versions of the clustering algorithm included too many
	nodes, making the clusters too large. This image shows how each node
	cluster that is started is independent of the previous ones. The clusters
	were identified in the order they are listed on the right.}\label{fig:multiple-clusters-colours}

\end{figure}

\subsection{Choosing Neighbours}
\label{sub:choosing_neighbours}

Some care must be taken when deciding what constitutes a neighbour of a node
and what does not. As mentioned above, when detecting clusters using
propagation, the neighbours of a node are checked and, if they are valid, are
themselves propagated. For this reason, a poor choice of neighbours means that
either the propagation will either:

\begin{itemize}
	\item be cut short too early, and so not all of the clusters will be
		located, or
	\item include too many nodes, in which case the clusters will not represent
		the actual data.
\end{itemize}

The first neighbours that must be considered, named \emph{rook's case}
neighbours by~\cite{abel1990comparative}, are the four nodes that lie to the
north, east, sound and west of the current node. These are the nodes that are
directly in contact with the node and so, if they are valid, represent a direct
continuation of the cluster.

However, if the choice of neighbours is limited to these four, some major
structures are missed. Figure~\ref{fig:kernel-rooks-case} shows how this
arrangement misses a large portion of the cluster, simply because the
propagation could not consider the nodes across the boundary. If, in addition
to the rook's case, the four \emph{diagonal} neighbours are included, giving a
total of eight, the results are much more complete, as shown in
Figure~\ref{fig:kernel-all8}.

\begin{figure}[tbhp]
	\centering
	\begin{subfigure}[b]{4.2cm}
		\includegraphics[width=\textwidth]{clusters/kernel-rooks-case.png}
		\caption{}\label{fig:kernel-rooks-case}
	\end{subfigure}%
	\quad
	\begin{subfigure}[b]{4.2cm}
		\includegraphics[width=\textwidth]{clusters/kernel-all8.png}
		\caption{}\label{fig:kernel-all8}
	\end{subfigure}

	\caption{A comparison between different neighbour sets.
		\subref{fig:kernel-rooks-case} shows how some of the cluster is lost
		when using just the rook's case neighbours, whereas, using all eight
		neighbours, Figure~\subref{fig:kernel-all8} more of the cluster is
		included.}\label{fig:kernel-options}

\end{figure}

The requirement to include a total of eight neighbours for each node suggests
that it might be of value to be able to specify an arbitrary number of
neighbours around the given cell.

In many applications in image processing, the concept of an image \emph{kernel}
is commonplace. This is a square, odd-sided matrix that is used to apply
filters and other effects to an image. The kernel is placed over each of the
pixels in the image in turn so that the central element in the matrix is over
the current pixel and each of the other elements is over another pixel. The
value of the element in the kernel is then used to manipulate the pixels in the
image below it. For example, to blur an image, a $3\times 3$ kernel composed of
all $\rfrac{1}{9}$'s can be used. When applied, this would mean that the
current pixel is given a value which is the sum of each of matrix elements
multiplied by the pixel value beneath it.

A similar technique is used to choose neighbours from the quadtree. The image
kernel that is used is a binary matrix, meaning that all of the elements are
restricted to 0 or 1, but, in all other respects, is the same as a regular
image kernel. The kernel is placed over a node of interest. Any nodes that lie
under an element with a value of 1 is included as a neighbour and 0 elements
are ignored so that no neighbours are chosen. The value of the central element
in the kernel does not matter, but the convention shall be to set this to 1.

Thus, the simpest kernel, though of least use, is the identity kernel which has
an element with value 1 in the center and all other elements 0. This would
result in no neighbours being selected, and so no clusters located. The rook's
case neighbours are now represented with the first kernel in
Figure~\ref{fig:kernel-neighbours}.
% TODO kernel explanation

\begin{figure}[tbhp]
	\centering
	\begin{subtable}[b]{0.2\textwidth}
	\centering
		\begin{tabular}{|l|l|l|}
			\hline
			0 & 1 & 0 \\
			\hline
			1 & \cellcolor{lblue}1 & 1 \\
			\hline
			0 & 1 & 0 \\
			\hline
		\end{tabular}
		\caption{}\label{fig:kernel-image-rooks}
	\end{subtable}%
	\quad
	\begin{subtable}[b]{0.2\textwidth}
	\centering
		\begin{tabular}{|l|l|l|}
			\hline
			1 & 1 & 1 \\
			\hline
			1 & \cellcolor{lblue}1 & 1 \\
			\hline
			1 & 1 & 1 \\
			\hline
		\end{tabular}
		\caption{}\label{fig:kernel-image-all8}
	\end{subtable}
	% TODO caption
	\caption{}\label{fig:kernel-neighbours}
\end{figure}

% TODO searching up the tree
% TODO searching down the tree
